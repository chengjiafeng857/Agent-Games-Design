# stage2_llm_refiner.py - Stage 2: LLM-Powered Prompt Refinement
#
# Pipeline Stage: Text Spec → Base Prompts → [LLM REFINEMENT] → Checklist → Image Gen
#                                              ^^^^^^^^^^^^^^^^
#                                              THIS STAGE
#
# This module uses OpenAI GPT-5 (with optional web search) to refine
# the base prompts into high-quality, optimized prompts for image generation.
#
# Unlike the static meta-prompts in stage2_gemini_prompts.py, this module
# ACTUALLY CALLS an LLM API to generate refined prompts automatically.
#
# REQUIRES:
#   - OPENAI_API_KEY environment variable set
#   - openai package installed (pip install openai)
#
# API OPTIONS:
#   Responses API (recommended): Uses GPT-5 with web_search tool
#      - models: "gpt-5", "gpt-5-mini", "gpt-5-nano", "gpt-4.1"
#      - web search: tools=[{"type": "web_search"}]
#   
#   See: https://platform.openai.com/docs/guides/tools-web-search
#
# Output:
#   - Refined prompts ready to use directly in image generators
#   - T-pose specific prompts for 3D modeling reference

import os
from dataclasses import dataclass
from typing import Optional

from .models import CharacterSpec
from .stage1_base_prompts import (
    format_color_palette,
    format_key_props,
    format_animation_focus,
    format_extra_notes,
)


# -----------------------------------------------------------------------------
# CONFIGURATION
# -----------------------------------------------------------------------------

# Environment variable NAME for OpenAI API key (NOT the actual key!)
# Set your key with: export OPENAI_API_KEY='sk-...'
OPENAI_API_KEY_ENV = "OPENAI_API_KEY"

# =============================================================================
# AVAILABLE MODELS (from OpenAI API docs - December 2025)
# =============================================================================
#
# RESPONSES API (recommended) - supports web_search tool:
#   gpt-5         - Flagship reasoning model with configurable effort
#   gpt-5-mini    - Faster, cost-efficient version of GPT-5
#   gpt-5-nano    - Fastest, most cost-efficient version of GPT-5
#   gpt-4.1       - Smartest non-reasoning model (1M token context)
#   gpt-4.1-mini  - Smaller, faster version of GPT-4.1
#
# Web search is enabled via tools=[{"type": "web_search"}] parameter
# NOT via a special model name!
#
# =============================================================================

# Default model for Responses API (GPT-5 with reasoning)
DEFAULT_MODEL = "gpt-5"

# Whether to use Responses API (True) or Chat Completions (False)
# Responses API is recommended for GPT-5 models with web_search tool
USE_RESPONSES_API = True


# -----------------------------------------------------------------------------
# DATA CLASSES
# -----------------------------------------------------------------------------

@dataclass
class RefinedPrompts:
    """
    Holds the refined prompts generated by the LLM.
    
    These prompts are ready to use directly in image generators
    (Midjourney, DALL-E, Stable Diffusion, Gemini, etc.)
    
    Attributes:
        concept_prompt: Refined full-body concept art prompt
        tpose_front: T-pose front view prompt (for 3D reference)
        tpose_side: T-pose side view prompt
        tpose_back: T-pose back view prompt
        model_used: Which LLM model was used
        web_search_used: Whether web search was enabled
    """
    concept_prompt: str
    tpose_front: str
    tpose_side: str
    tpose_back: str
    model_used: str
    web_search_used: bool


# -----------------------------------------------------------------------------
# SYSTEM PROMPTS FOR THE LLM
# -----------------------------------------------------------------------------

# System prompt that defines the LLM's role and behavior
SYSTEM_PROMPT_BASE = """You are an expert AI art prompt engineer specializing in game character concept art.

Your job is to take a character specification and create highly effective prompts for AI image generators (like Midjourney, DALL-E, Stable Diffusion, or Gemini).

Key principles for your prompts:
1. Be SPECIFIC and DETAILED - vague prompts produce generic results
2. Include art style references that match the game style
3. Specify lighting, camera angle, and composition clearly
4. Mention technical requirements (resolution, no text, clean background)
5. Use terminology that AI image models understand well

For T-pose reference images (used in 3D modeling/rigging):
- Arms must be extended horizontally (like letter T)
- Full body visible from head to feet
- CRITICAL FOR 3D RIGGING: The structure of both knees must be completely visible and unobstructed
- If character wears a long coat, robe, or dress, it MUST be open, short, or pulled back to expose full leg structure
- Show clear leg anatomy: thighs, knees, shins, and feet must all be visible - no clothing hiding knee joints
- Clean, simple background (white or light gray)
- Even, neutral lighting (no dramatic shadows)
- No props that obscure the body shape
- No text, logos, or watermarks
- Symmetrical, neutral pose

Output ONLY the prompt text, with no explanation or commentary."""

SYSTEM_PROMPT_WITH_SEARCH = """You are an expert AI art prompt engineer with access to web search.

Before generating prompts, search for:
1. Current AI art prompt trends and best practices
2. Popular style keywords that work well with image generators
3. Reference images of similar character types

Then create highly effective prompts following these principles:
1. Be SPECIFIC and DETAILED - vague prompts produce generic results
2. Include art style references that match the game style
3. Specify lighting, camera angle, and composition clearly
4. Use currently trending keywords that AI models respond well to
5. Mention technical requirements (resolution, no text, clean background)

For T-pose reference images (used in 3D modeling/rigging):
- Arms must be extended horizontally (like letter T)
- Full body visible from head to feet
- CRITICAL FOR 3D RIGGING: The structure of both knees must be completely visible and unobstructed
- If character wears a long coat, robe, or dress, it MUST be open, short, or pulled back to expose full leg structure
- Show clear leg anatomy: thighs, knees, shins, and feet must all be visible - no clothing hiding knee joints
- Clean, simple background (white or light gray)
- Even, neutral lighting (no dramatic shadows)
- No props that obscure the body shape
- No text, logos, or watermarks
- Symmetrical, neutral pose

Output ONLY the prompt text, with no explanation or commentary."""


# -----------------------------------------------------------------------------
# USER PROMPT TEMPLATES
# -----------------------------------------------------------------------------

def build_concept_request(spec: CharacterSpec) -> str:
    """Build the user request for a concept art prompt."""
    color_str = format_color_palette(spec.color_palette)
    props_str = format_key_props(spec.key_props)
    anim_str = format_animation_focus(spec.animation_focus)
    notes_str = format_extra_notes(spec.extra_notes)
    
    return f"""Create a detailed prompt for generating a full-body character concept art.

Character Specification:
- Name: {spec.name}
- Role: {spec.role}
- Game Style: {spec.game_style}
- Silhouette: {spec.silhouette}
- Color Palette: {color_str}
- Key Props: {props_str}
- Animation Focus: {anim_str}
- Extra Notes: {notes_str}

The prompt should produce a clean, professional character concept suitable for game development."""


def build_tpose_request(spec: CharacterSpec, view: str) -> str:
    """Build the user request for a T-pose prompt."""
    color_str = format_color_palette(spec.color_palette)
    props_str = format_key_props(spec.key_props)
    
    view_descriptions = {
        "front": "FRONT VIEW - character facing the camera directly",
        "side": "SIDE VIEW - character in profile, facing left",
        "back": "BACK VIEW - character facing away from camera",
    }
    
    return f"""Create a detailed prompt for generating a T-pose character reference image.

Character Specification:
- Name: {spec.name}
- Role: {spec.role}
- Game Style: {spec.game_style}
- Silhouette: {spec.silhouette}
- Color Palette: {color_str}
- Key Props: {props_str}

Required View: {view_descriptions.get(view, view)}

The prompt must specify:
1. T-pose with arms extended horizontally
2. Full body from head to feet
3. CRITICAL: Knee structure must be visible - if character has long coat/robe/dress, it must be open or short to show full leg anatomy
4. Clean white/gray background
5. Even studio lighting
6. No text or watermarks
7. Professional game character art quality"""


# -----------------------------------------------------------------------------
# OPENAI API INTEGRATION
# -----------------------------------------------------------------------------

def get_openai_api_key() -> str:
    """
    Get the OpenAI API key from environment variable.
    
    Returns:
        The API key string
        
    Raises:
        ValueError: If the API key is not set
    """
    api_key = os.environ.get(OPENAI_API_KEY_ENV)
    
    if not api_key:
        raise ValueError(
            f"OpenAI API key not found.\n"
            f"Please set the {OPENAI_API_KEY_ENV} environment variable:\n"
            f"  export {OPENAI_API_KEY_ENV}='your-api-key-here'"
        )
    
    return api_key


def call_openai_responses_api(
    user_message: str,
    api_key: str,
    model: str = DEFAULT_MODEL,
    use_web_search: bool = False,
) -> str:
    """
    Call OpenAI using the Responses API (supports web_search tool).
    
    The Responses API is the newer API that supports tools like web_search.
    It's recommended for GPT-5 models.
    
    Args:
        user_message: The user's request (character spec + instructions)
        api_key: OpenAI API key
        model: Model to use (default: gpt-5)
        use_web_search: Whether to enable web search tool
        
    Returns:
        The generated prompt text
    """
    try:
        from openai import OpenAI
    except ImportError:
        raise ImportError(
            "openai package is required for LLM prompt refinement.\n"
            "Install it with: pip install openai\n"
            "Or: uv add openai"
        )
    
    client = OpenAI(api_key=api_key)
    
    # Build the full input with system context
    system_context = SYSTEM_PROMPT_WITH_SEARCH if use_web_search else SYSTEM_PROMPT_BASE
    full_input = f"{system_context}\n\n---\n\n{user_message}"
    
    # Configure tools
    tools = [{"type": "web_search"}] if use_web_search else None
    
    # Make the API call using Responses API
    response = client.responses.create(
        model=model,
        input=full_input,
        tools=tools,
    )
    
    # Extract the response text
    return response.output_text.strip()


def call_openai_chat_completions(
    user_message: str,
    api_key: str,
    model: str = DEFAULT_MODEL,
    use_web_search: bool = False,
) -> str:
    """
    Call OpenAI using the Chat Completions API (fallback).
    
    NOTE: For web search, Chat Completions requires a specialized model.
    However, the Responses API with tools=[{"type": "web_search"}] is
    the recommended approach as of 2025.
    
    Args:
        user_message: The user's request (character spec + instructions)
        api_key: OpenAI API key
        model: Model to use (default: gpt-5)
        use_web_search: Whether web search was requested (not supported here)
        
    Returns:
        The generated prompt text
    """
    try:
        from openai import OpenAI
    except ImportError:
        raise ImportError(
            "openai package is required for LLM prompt refinement.\n"
            "Install it with: pip install openai\n"
            "Or: uv add openai"
        )
    
    # Chat Completions doesn't support web_search tool directly
    # Web search requires Responses API, so we just use the base prompt here
    if use_web_search:
        print("  Note: Web search requires Responses API. Using standard completion.")
    
    system_prompt = SYSTEM_PROMPT_BASE
    
    client = OpenAI(api_key=api_key)
    
    # Make the API call using Chat Completions
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message},
        ],
        temperature=0.7,
        max_tokens=1000,
    )
    
    return response.choices[0].message.content.strip()


def call_openai(
    user_message: str,
    api_key: str,
    model: str = DEFAULT_MODEL,
    use_web_search: bool = False,
) -> str:
    """
    Call the OpenAI API to generate a refined prompt.
    
    Automatically selects the best API based on configuration:
    - Responses API: For GPT-5 with web_search tool (recommended)
    - Chat Completions: For older models or fallback
    
    Args:
        user_message: The user's request (character spec + instructions)
        api_key: OpenAI API key
        model: Model to use (default: gpt-5)
        use_web_search: Whether to enable web search capability
        
    Returns:
        The generated prompt text
        
    Raises:
        ImportError: If openai package is not installed
        Exception: If the API call fails
    """
    if USE_RESPONSES_API:
        try:
            return call_openai_responses_api(
                user_message=user_message,
                api_key=api_key,
                model=model,
                use_web_search=use_web_search,
            )
        except Exception as e:
            # Fall back to Chat Completions if Responses API fails
            print(f"  Warning: Responses API failed ({e}), falling back to Chat Completions...")
            return call_openai_chat_completions(
                user_message=user_message,
                api_key=api_key,
                model=model,
                use_web_search=use_web_search,
            )
    else:
        return call_openai_chat_completions(
            user_message=user_message,
            api_key=api_key,
            model=model,
            use_web_search=use_web_search,
        )


# -----------------------------------------------------------------------------
# MAIN REFINEMENT FUNCTION
# -----------------------------------------------------------------------------

def refine_prompts_with_llm(
    spec: CharacterSpec,
    api_key: Optional[str] = None,
    model: str = DEFAULT_MODEL,
    use_web_search: bool = False,
) -> RefinedPrompts:
    """
    Use OpenAI GPT to refine prompts for a character.
    
    This function makes multiple API calls to generate:
    1. A refined concept art prompt
    2. T-pose prompts for front, side, and back views
    
    Args:
        spec: The character specification
        api_key: Optional API key (uses OPENAI_API_KEY env var if not provided)
        model: OpenAI model to use (default: gpt-5)
        use_web_search: Enable web search tool for current trends (default: False)
        
    Returns:
        RefinedPrompts object containing all generated prompts
        
    Example:
        >>> prompts = refine_prompts_with_llm(spec, use_web_search=True)
        >>> print(prompts.tpose_front)
    """
    # Get API key
    if api_key is None:
        api_key = get_openai_api_key()
    
    # Determine which model/API will be used
    api_type = "Responses API" if USE_RESPONSES_API else "Chat Completions"
    
    print(f"  Using: {api_type}")
    print(f"  Model: {model}")
    print(f"  Web search: {'enabled (web_search tool)' if use_web_search else 'disabled'}")
    
    # Generate concept prompt
    print("  Generating concept art prompt...")
    concept_request = build_concept_request(spec)
    concept_prompt = call_openai(
        user_message=concept_request,
        api_key=api_key,
        model=model,
        use_web_search=use_web_search,
    )
    
    # Generate T-pose prompts for each view
    tpose_prompts = {}
    for view in ["front", "side", "back"]:
        print(f"  Generating {view} T-pose prompt...")
        tpose_request = build_tpose_request(spec, view)
        tpose_prompts[view] = call_openai(
            user_message=tpose_request,
            api_key=api_key,
            model=model,
            use_web_search=use_web_search,
        )
    
    print("  ✓ All prompts refined")
    
    return RefinedPrompts(
        concept_prompt=concept_prompt,
        tpose_front=tpose_prompts["front"],
        tpose_side=tpose_prompts["side"],
        tpose_back=tpose_prompts["back"],
        model_used=model,
        web_search_used=use_web_search,
    )


# -----------------------------------------------------------------------------
# DICTIONARY OUTPUT (FOR FILE SAVING)
# -----------------------------------------------------------------------------

def refine_prompts_to_dict(
    spec: CharacterSpec,
    api_key: Optional[str] = None,
    model: str = DEFAULT_MODEL,
    use_web_search: bool = False,
) -> dict[str, str]:
    """
    Refine prompts and return as a dictionary (for saving to files).
    
    Args:
        spec: The character specification
        api_key: Optional API key
        model: OpenAI model to use
        use_web_search: Enable web search
        
    Returns:
        Dictionary mapping prompt keys to prompt content
    """
    refined = refine_prompts_with_llm(
        spec=spec,
        api_key=api_key,
        model=model,
        use_web_search=use_web_search,
    )
    
    return {
        "refined_concept": refined.concept_prompt,
        "refined_tpose_front": refined.tpose_front,
        "refined_tpose_side": refined.tpose_side,
        "refined_tpose_back": refined.tpose_back,
    }


# -----------------------------------------------------------------------------
# PREVIEW MODE (NO API CALLS)
# -----------------------------------------------------------------------------

def preview_llm_requests(spec: CharacterSpec) -> dict[str, str]:
    """
    Preview the requests that would be sent to the LLM.
    
    Useful for testing without making API calls.
    Shows what prompts would be refined.
    
    Args:
        spec: The character specification
        
    Returns:
        Dictionary mapping request names to request content
    """
    return {
        "concept_request": build_concept_request(spec),
        "tpose_front_request": build_tpose_request(spec, "front"),
        "tpose_side_request": build_tpose_request(spec, "side"),
        "tpose_back_request": build_tpose_request(spec, "back"),
    }

